{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46fb1d08",
   "metadata": {},
   "source": [
    "### Importing the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc75ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368e5e03",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b158d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.75\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "model = keras.models.load_model('traffif_sign_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87abb83f",
   "metadata": {},
   "source": [
    "### Preprocessing for sign detection in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a2801f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(imgBGR, erode_dilate = True):\n",
    "    rows, cols, _ = imgBGR.shape\n",
    "    imgHSV = cv2.cvtColor(imgBGR, cv2.COLOR_BGR2HSV)\n",
    "    Bmin = np.array([100, 43,46])\n",
    "    Bmax = np.array([124, 255, 255])\n",
    "    img_Bbin = cv2.inRange(imgHSV, Bmin, Bmax)\n",
    "    \n",
    "    Rmin1 = np.array([0, 43, 46])\n",
    "    Rmax1 = np.array([10, 255, 255])\n",
    "    img_Rbin1 = cv2.inRange(imgHSV, Rmin1, Rmax1)\n",
    "    \n",
    "    Rmin2 = np.array([156, 43, 46])\n",
    "    Rmax2 = np.array([180, 255, 255])\n",
    "    img_Rbin2 = cv2.inRange(imgHSV, Rmin2, Rmax2)\n",
    "    \n",
    "    img_Rbin = np.maximum(img_Rbin1, img_Rbin2)\n",
    "    img_bin = np.maximum(img_Bbin, img_Rbin)\n",
    "    \n",
    "    if erode_dilate is True:\n",
    "        kernelErosion = np.ones((3,3), np.uint8)\n",
    "        kernelDilation = np.ones((3,3), np.uint8)\n",
    "        img_bin = cv2.erode(img_bin, kernelErosion, iterations = 2)\n",
    "        img_bin = cv2.dilate(img_bin, kernelDilation, iterations = 2)\n",
    "    \n",
    "    return img_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3587cb",
   "metadata": {},
   "source": [
    "### Count traffic sings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d65fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to count the total number of traffic signs in a single frame\n",
    "def contour_detect(img_bin, min_area, max_area = -1, wh_ratio = 2.0):\n",
    "    rects = []\n",
    "    contours, _ = cv2.findContours(img_bin.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    if len(contours) == None:\n",
    "        return rects\n",
    "    if max_area<0:\n",
    "        max_area = img_bin.shape[0] * img_bin.shape[1] \n",
    "    else:\n",
    "        max_area\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area >= min_area and area <= max_area:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            if 1.0 * w/h < wh_ratio and 1.0 * h/w < wh_ratio:\n",
    "                rects.append([x, y, w, h])\n",
    "    return rects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221404cf",
   "metadata": {},
   "source": [
    "### Preprocessing the image before prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55ee808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "\n",
    "def equalize(img):\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img\n",
    "def preprocessing(img):\n",
    "    img = grayscale(img)\n",
    "    img = equalize(img)\n",
    "    img = img / 255\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf61cf3",
   "metadata": {},
   "source": [
    "### Function for returning the class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a58b1a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(classNo):\n",
    "    if classNo == 0:\n",
    "        return 'Speed Limit 20 km/h'\n",
    "    elif classNo == 1:\n",
    "        return 'Speed Limit 30 km/h'\n",
    "    elif classNo == 2:\n",
    "        return 'Speed Limit 50 km/h'\n",
    "    elif classNo == 3:\n",
    "        return 'Speed Limit 60 km/h'\n",
    "    elif classNo == 4:\n",
    "        return 'Speed Limit 70 km/h'\n",
    "    elif classNo == 5:\n",
    "        return 'Speed Limit 80 km/h'\n",
    "    elif classNo == 6:\n",
    "        return 'End of Speed Limit 80 km/h'\n",
    "    elif classNo == 7:\n",
    "        return 'Speed Limit 100 km/h'\n",
    "    elif classNo == 8:\n",
    "        return 'Speed Limit 120 km/h'\n",
    "    elif classNo == 9:\n",
    "        return 'No passing'\n",
    "    elif classNo == 10:\n",
    "        return 'No passing for vechiles over 3.5 metric tons'\n",
    "    elif classNo == 11:\n",
    "        return 'Right-of-way at the next intersection'\n",
    "    elif classNo == 12:\n",
    "        return 'Priority road'\n",
    "    elif classNo == 13:\n",
    "        return 'Yield'\n",
    "    elif classNo == 14:\n",
    "        return 'Stop'\n",
    "    elif classNo == 15:\n",
    "        return 'No vechiles'\n",
    "    elif classNo == 16:\n",
    "        return 'Vechiles over 3.5 metric tons prohibited'\n",
    "    elif classNo == 17:\n",
    "        return 'No entry'\n",
    "    elif classNo == 18:\n",
    "        return 'General caution'\n",
    "    elif classNo == 19:\n",
    "        return 'Dangerous curve to the left'\n",
    "    elif classNo == 20:\n",
    "        return 'Dangerous curve to the right'\n",
    "    elif classNo == 21:\n",
    "        return 'Double curve'\n",
    "    elif classNo == 22:\n",
    "        return 'Bumpy road'\n",
    "    elif classNo == 23:\n",
    "        return 'Slippery road'\n",
    "    elif classNo == 24:\n",
    "        return 'Road narrows on the right'\n",
    "    elif classNo == 25:\n",
    "        return 'Road work'\n",
    "    elif classNo == 26:\n",
    "        return 'Traffic signals'\n",
    "    elif classNo == 27:\n",
    "        return 'Pedestrians'\n",
    "    elif classNo == 28:\n",
    "        return 'Children crossing'\n",
    "    elif classNo == 29:\n",
    "        return 'Bicycles crossing'\n",
    "    elif classNo == 30:\n",
    "        return 'Beware of ice/snow'\n",
    "    elif classNo == 31:\n",
    "        return 'Wild animals crossing'\n",
    "    elif classNo == 32:\n",
    "        return 'End of all speed and passing limits'\n",
    "    elif classNo == 33:\n",
    "        return 'Turn right ahead'\n",
    "    elif classNo == 34:\n",
    "        return 'Turn left ahead'\n",
    "    elif classNo == 35:\n",
    "        return 'Ahead only'\n",
    "    elif classNo == 36:\n",
    "        return 'Go straight or right'\n",
    "    elif classNo == 37:\n",
    "        return 'Go straight or left'\n",
    "    elif classNo == 38:\n",
    "        return 'Keep right'\n",
    "    elif classNo == 39:\n",
    "        return 'Keep left'\n",
    "    elif classNo == 40:\n",
    "        return 'Roundabout mandatory'\n",
    "    elif classNo == 41:\n",
    "        return 'End of no passing'\n",
    "    elif classNo == 42:\n",
    "        return 'End of no passing by vechiles over 3.5 metric tons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5823d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cols = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    rows = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    while(1):\n",
    "        ret, img = cap.read()\n",
    "        img_bin = preprocess_img(img, erode_dilate=False)\n",
    "        cv2.imshow(\"Bin_image\",img_bin)\n",
    "        min_area = img_bin.shape[0] * img.shape[1] / (25 * 25)\n",
    "        rects = contour_detect(img_bin, min_area = min_area) #get x,y,w,h\n",
    "        img_bbx = img.copy()\n",
    "        for rect in rects:\n",
    "            # rect[2] is width and rect[3] for height\n",
    "            xc = int(rect[0] + rect[2] / 2)\n",
    "            yc = int(rect[1] + rect[3] / 2)\n",
    "            \n",
    "            size = max(rect[2], rect[3])\n",
    "            x1 = int(max(0, (xc - size / 2)))\n",
    "            y1 = int(max(0, (yc - size / 2)))\n",
    "            x2 = int(min(cols, int(xc + size / 2)))\n",
    "            y2 = int(min(rows, int(yc + size / 2)))\n",
    "            \n",
    "            if rect[2] > 100 and rect[3] > 100:\n",
    "                cv2.rectangle(img_bbx, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 0, 255), 2)\n",
    "            \n",
    "            crop_img = np.asarray(img[y1:y2, x1:x2])\n",
    "            crop_img = cv2.resize(crop_img, (32,32))\n",
    "            crop_img = preprocessing(crop_img)\n",
    "            cv2.imshow(\"afterprocessing\", crop_img)\n",
    "            crop_img = crop_img.reshape(1, 32, 32, 1) #(1,32,32) after reshape it become (1,32,32,1)\n",
    "            \n",
    "            #make prediction\n",
    "            predictions = model.predict(crop_img)\n",
    "            classIndex = np.argmax(predictions, axis = 1)\n",
    "            probabilityValue = np.amax(predictions)\n",
    "            if probabilityValue > threshold:\n",
    "                #write class name on the output screen\n",
    "                cv2.putText(img_bbx, str(classIndex) + \" \" + str(get_class(classIndex)), (rect[0], rect[1] - 10), \n",
    "                           font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                # write probability value on the output screen\n",
    "                cv2.putText(img_bbx, str(round(probabilityValue * 100, 2)) + \"%\", (rect[0], rect[1] - 40), font, 0.75,\n",
    "                            (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        cv2.imshow(\"detect result\", img_bbx)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):           # q for quit \n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
